# PaperSummary

東京理科大学 応用数学研究部(OSK) DeepLearning班 論文読み会の発表資料

## 論文
- Cross-Entropy-Loss*
- [Deep Learning for Bug-Localization in Student Programs](https://arxiv.org/abs/1905.12454)*
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
- [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942)*
- [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165?source=techstories.org)*
- [It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners](https://arxiv.org/abs/2009.07118)*
- [Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference](https://arxiv.org/abs/2001.07676)
- [Few-shot Font Generation with Localized Style Representations and Factorization](https://arxiv.org/abs/2009.11042)*
- [What's New? Summarizing Contributions in Scientific Literature](https://arxiv.org/abs/2011.03161v2)
- word2vec*

(*はスライド作成済み)
